{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95e6757d",
   "metadata": {},
   "source": [
    "### Important:\n",
    "The data used in this exercise has already been cleaned. However, I included this notebook with a basic data cleaning step, as the process may vary depending on the context. For example, if the token is a stablecoin, it might be necessary to remove very small or very large values. Zero-value transactions could be relevant for identifying network activity, or they might indicate failed transactions or contract issues. Repeated values in short time spans may suggest arbitrage or testing behaviour. Therefore, the cleaning strategy should be adapted to the analysis goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e5625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/token_transfers_V3.0.0.csv')\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800b0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df_excluded = pd.DataFrame()\n",
    "\n",
    "# standardizations (valid with etherium)\n",
    "df['from_address'] = df['from_address'].str.lower()\n",
    "df['to_address'] = df['to_address'].str.lower()\n",
    "df['contract_address'] = df['contract_address'].str.lower()\n",
    "\n",
    "# Basic function to validate ethereum address\n",
    "def is_valid_eth_address(addr):\n",
    "    return isinstance(addr, str) and re.fullmatch(r\"0x[a-f0-9]{40}\", addr) is not None\n",
    "\n",
    "# Remove lines with missing data in essential columns\n",
    "essential_cols = ['block_number', 'transaction_index', 'from_address', 'to_address', 'time_stamp', 'contract_address', 'value']\n",
    "missing_rows = df[df[essential_cols].isnull().any(axis=1)]\n",
    "df_excluded = pd.concat([df_excluded, missing_rows])\n",
    "df = df.drop(missing_rows.index.tolist())\n",
    "\n",
    "# Remove trasactions with value < 0\n",
    "zero_value_rows = df[df['value'] < 0.0]\n",
    "df_excluded = pd.concat([df_excluded, zero_value_rows])\n",
    "df = df.drop(zero_value_rows.index.tolist())\n",
    "\n",
    "# Remove invalid address\n",
    "invalid_from = df[~df['from_address'].apply(is_valid_eth_address)]\n",
    "invalid_to = df[~df['to_address'].apply(is_valid_eth_address)]\n",
    "invalid_contract = df[~df['contract_address'].apply(is_valid_eth_address)]\n",
    "invalid_rows = pd.concat([invalid_from, invalid_to, invalid_contract]).drop_duplicates()\n",
    "df_excluded = pd.concat([df_excluded, invalid_rows])\n",
    "df = df.drop(invalid_rows.index.tolist())\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df['time_stamp'] = pd.to_datetime(df['time_stamp'], unit='s')\n",
    "df['date'] = df['time_stamp'].dt.date\n",
    "\n",
    "# Summary\n",
    "print(f\"Total original: {len(df) + len(df_excluded)}\")\n",
    "print(f\"Valids: {len(df)}\")\n",
    "print(f\"Excludeds: {len(df_excluded)}\")\n",
    "print(f\"Tax of validation: {(len(df) / (len(df) + len(df_excluded)) * 100):.2f}%\")\n",
    "df_excluded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c1f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic descriptive statistics\n",
    "print(\"Descriptive:\")\n",
    "print(df['value'].describe())\n",
    "print(f\"\\nPerccentiles: {df['value'].quantile([0.001, 0.01, 0.05, 0.95, 0.99, 0.999])}\")\n",
    "\n",
    "# Identify imposible values\n",
    "test_values = df[df['value'] >= 1e15]\n",
    "print(f\"\\nExtreme values (>= 1e15): {len(test_values)}\")\n",
    "\n",
    "# Analisys per contract\n",
    "print(\"\\nAnalisys per contract:\")\n",
    "for contract in df['contract_address'].value_counts().head(5).index:\n",
    "    contract_data = df[df['contract_address'] == contract]\n",
    "    print(f\"{str(contract)[:10]}...: min={contract_data['value'].min():.4f}, max={contract_data['value'].max():.4f}\")\n",
    "\n",
    "# Remove outliers\n",
    "q_high = df['value'].quantile(0.9999) # 99.99%\n",
    "q_low = df['value'].quantile(0.0001) # 0.01%\n",
    "\n",
    "outlier_high = df[df['value'] > q_high]\n",
    "outlier_low = df[df['value'] < q_low]\n",
    "\n",
    "print(f\"\\nHighest outliers (> {q_high:.2f}): {len(outlier_high)}\")\n",
    "print(f\"Lowest outliers (< {q_low:.2f}): {len(outlier_low)}\")\n",
    "\n",
    "# Remove and update tracking\n",
    "df_excluded = pd.concat([df_excluded, outlier_high, outlier_low])\n",
    "df = df[(df['value'] >= q_low) & (df['value'] <= q_high)]\n",
    "\n",
    "print(f\"\\nAfter outliers removal: {len(df)} valid transactions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
